{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"Lab3_Seq2Seq LSTM Model - Translation_with_prediction.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"tPoWUqT_fl6F","colab_type":"text"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"id":"UktC6KA3fl6I","colab_type":"code","outputId":"7b01432a-07d8-4e9e-a345-a8a09f8db8d9","executionInfo":{"status":"ok","timestamp":1578045132596,"user_tz":-330,"elapsed":3750,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["import tensorflow as tf\n","tf.reset_default_graph()\n","tf.set_random_seed(42)"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZwMcmvGYfl6O","colab_type":"text"},"source":["### Read the data\n","<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"]},{"cell_type":"code","metadata":{"id":"ka8Cdm70fl6P","colab_type":"code","colab":{}},"source":["#You can use wget to download the file directly\n","!wget http://www.manythings.org/anki/hin-eng.zip --quiet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjnQuAQpfl6T","colab_type":"code","colab":{}},"source":["import zipfile\n","import io\n","\n","#Read the zip file\n","zf = zipfile.ZipFile('hin-eng.zip', 'r')\n","\n","#Extract data from zip file\n","data = ''\n","with zf.open('hin.txt') as readfile:\n","  for line in io.TextIOWrapper(readfile, 'utf-8'):\n","    data += line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdZpfjIAfl6X","colab_type":"code","outputId":"96efc91b-4280-41c9-b88f-dc8f47320a1b","executionInfo":{"status":"ok","timestamp":1578045218868,"user_tz":-330,"elapsed":1108,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(data)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["401994"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"RTvBSCbqfl6a","colab_type":"code","outputId":"f0d018cf-e472-4104-cb2e-40bb39577b1a","executionInfo":{"status":"ok","timestamp":1578045264477,"user_tz":-330,"elapsed":1285,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["data[0:120]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Wow!\\tवाह!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #6179147 (fastrizwaan)\\nHelp!\\tबचाओ!\\tCC-BY 2.0 (Fra'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"6PWF6Yj8fl6d","colab_type":"text"},"source":["\n","### Extract Source and Target Language pairs"]},{"cell_type":"code","metadata":{"id":"of7oqLQ6fl6e","colab_type":"code","outputId":"1a30343a-886e-4be1-d2ef-714e68f449b6","executionInfo":{"status":"ok","timestamp":1578046439717,"user_tz":-330,"elapsed":1288,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["#Split by newline character\n","data =  data.split('\\n')\n","\n","#Show some Data\n","data[100:105]"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I don't know.\\tमुझे नहीं पता।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609376 (minshirui)\",\n"," \"I don't know.\\tमुझे नहीं मालूम।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609377 (minshirui)\",\n"," 'I have a car.\\tमेरे पास एक गाड़ी है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #252272 (CK) & #477720 (minshirui)',\n"," 'I have a dog.\\tमेरे पास एक कुत्ता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #378502 (CK) & #443037 (minshirui)',\n"," 'I understand.\\tमैं समझता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433468 (CK) & #588495 (minshirui)']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"a_prK6e-wnpO","colab_type":"code","colab":{}},"source":["temp = \"I don't know.\\tमुझे नहीं पता।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609376 (minshirui)\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LI3nRNuawrMS","colab_type":"code","outputId":"600f459a-97fa-45e8-9321-ae9e9b58349d","executionInfo":{"status":"ok","timestamp":1578046590375,"user_tz":-330,"elapsed":1125,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["temp.split(\"\\t\")"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I don't know.\",\n"," 'मुझे नहीं पता।',\n"," 'CC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609376 (minshirui)']"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"zAmaPZXVfl6h","colab_type":"code","outputId":"b9653ead-3afc-4bad-b34f-e2a4314a79d3","executionInfo":{"status":"ok","timestamp":1578012744947,"user_tz":-330,"elapsed":956,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2786"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"U2X7ztxhfl6l","colab_type":"text"},"source":["### Separate Source and Target pairs"]},{"cell_type":"code","metadata":{"id":"UiRGCQhofl6m","colab_type":"code","colab":{}},"source":["encoder_text = [] #Initialize Source language list\n","decoder_text = [] #Initialize Target language list\n","\n","#Iterate over data\n","for line in data:\n","    try:\n","        in_txt, out_txt, attr = line.split('\\t')\n","        encoder_text.append(in_txt)\n","        \n","        # Add tab '<start>' as 'start sequence in target\n","        # And '<end>' as End\n","        decoder_text.append('<start> ' + out_txt + ' <end>')\n","    except:\n","        pass #ignore data which goes into error        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zUsGJhXIfl6p","colab_type":"text"},"source":["### Separate Source and Target pairs.."]},{"cell_type":"code","metadata":{"id":"ljWhJKtdfl6q","colab_type":"code","outputId":"35c78f47-4e94-45e0-d21a-2025a89362f7","executionInfo":{"status":"ok","timestamp":1578046625555,"user_tz":-330,"elapsed":1304,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["encoder_text[100:105]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I don't know.\",\n"," \"I don't know.\",\n"," 'I have a car.',\n"," 'I have a dog.',\n"," 'I understand.']"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"HxvpUjChfl6v","colab_type":"code","outputId":"e38d6f0d-14b4-4edc-fb9e-4b500799d5af","executionInfo":{"status":"ok","timestamp":1578046633900,"user_tz":-330,"elapsed":1311,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["decoder_text[100:105]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> मुझे नहीं पता। <end>',\n"," '<start> मुझे नहीं मालूम। <end>',\n"," '<start> मेरे पास एक गाड़ी है। <end>',\n"," '<start> मेरे पास एक कुत्ता है। <end>',\n"," '<start> मैं समझता हूँ। <end>']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"H2lVLEdpg8a3","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"z24rR4h0fl6x","colab_type":"text"},"source":["### Tokenize Source language sentences"]},{"cell_type":"code","metadata":{"id":"am-SxejboRWG","colab_type":"code","outputId":"012695cd-660d-4fc5-f527-02fee69b531f","executionInfo":{"status":"ok","timestamp":1578046863739,"user_tz":-330,"elapsed":1215,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["encoder_text[100:105]"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I don't know.\",\n"," \"I don't know.\",\n"," 'I have a car.',\n"," 'I have a dog.',\n"," 'I understand.']"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"lyInIgzNfl6y","colab_type":"code","outputId":"a1e49573-aec8-46aa-9ebc-6dfe0c1f0b86","executionInfo":{"status":"ok","timestamp":1578046865139,"user_tz":-330,"elapsed":996,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#Tokenizer for source language\n","encoder_t = tf.keras.preprocessing.text.Tokenizer()\n","encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n","encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n","encoder_seq[100:105] #Display some converted sentences"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[2, 27, 43], [2, 27, 43], [2, 14, 6, 97], [2, 14, 6, 124], [2, 209]]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"-bsqH-9Ofl61","colab_type":"code","colab":{}},"source":["#encoder_t.word_index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrFed-2LzgPQ","colab_type":"code","outputId":"7006a0d6-efb7-49b2-da88-6c7a26382612","executionInfo":{"status":"ok","timestamp":1578047003672,"user_tz":-330,"elapsed":1715,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#Maximum length of sentence\n","max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n","print('Maximum sentence length for Source language: ', max_encoder_seq_length)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Maximum sentence length for Source language:  22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k0lMszoffl65","colab_type":"code","outputId":"bbff6aa4-3251-43ae-82bc-e49293e3088c","executionInfo":{"status":"ok","timestamp":1578047057021,"user_tz":-330,"elapsed":774,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#Source language Vocablury\n","encoder_vocab_size = len(encoder_t.word_index)\n","print('Source language vocablury size: ', encoder_vocab_size)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Source language vocablury size:  2376\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4vGYKXtLfl68","colab_type":"text"},"source":["### Tokenize Target language sentences"]},{"cell_type":"code","metadata":{"id":"juKB2LT-fl69","colab_type":"code","colab":{}},"source":["#Tokenizer for target language, filters should not <start> and <end>\n","#remove < and > used in Target language sequences\n","decoder_t = tf.keras.preprocessing.text.Tokenizer()\n","decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n","decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p9cp5y13pMos","colab_type":"code","outputId":"e2acc814-0a0e-4465-fe14-fb40708f58a3","executionInfo":{"status":"ok","timestamp":1578047136514,"user_tz":-330,"elapsed":1329,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["decoder_text[100:105]"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> मुझे नहीं पता। <end>',\n"," '<start> मुझे नहीं मालूम। <end>',\n"," '<start> मेरे पास एक गाड़ी है। <end>',\n"," '<start> मेरे पास एक कुत्ता है। <end>',\n"," '<start> मैं समझता हूँ। <end>']"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"ZiEUEjv8pG_f","colab_type":"code","outputId":"62c1eae0-773a-4558-d395-4385758d8ff3","executionInfo":{"status":"ok","timestamp":1578047143533,"user_tz":-330,"elapsed":1305,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["decoder_seq[100:105] #Display some converted sentences"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 10, 5, 615, 2],\n"," [1, 10, 5, 1479, 2],\n"," [1, 28, 40, 21, 101, 3, 2],\n"," [1, 28, 40, 21, 202, 3, 2],\n"," [1, 6, 764, 22, 2]]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"UBc04weZfl6_","colab_type":"code","outputId":"a5fb7423-5174-4c17-c6fb-499773f33f69","executionInfo":{"status":"ok","timestamp":1578047230915,"user_tz":-330,"elapsed":1136,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#Maximum length of sentence\n","max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n","print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n","\n","#Target language Vocablury\n","decoder_vocab_size = len(decoder_t.word_index)\n","print('Target language vocablury size: ', decoder_vocab_size)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Maximum sentence length for Target language:  27\n","Target language vocablury size:  2974\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G1yy4pK1fl7D","colab_type":"text"},"source":["### Compare different sentences length"]},{"cell_type":"code","metadata":{"id":"uGjnnsT6fl7E","colab_type":"code","outputId":"4548bc38-9f1e-4802-a2af-dbfc1eb71c5a","executionInfo":{"status":"ok","timestamp":1578047355010,"user_tz":-330,"elapsed":1242,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#Source Language sentences\n","print('Length for sentence number 100: ', len(encoder_seq[100]))\n","print('Length for sentence number 2000: ', len(encoder_seq[2000]))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Length for sentence number 100:  3\n","Length for sentence number 2000:  6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tk4wXJwDfl7H","colab_type":"code","outputId":"84670301-a23d-4c1b-cba5-5f43b9f64a81","executionInfo":{"status":"ok","timestamp":1578047363836,"user_tz":-330,"elapsed":1158,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#Target Language sentences\n","print('Length for sentence number 100: ', len(decoder_seq[100]))\n","print('Length for sentence number 2000: ', len(decoder_seq[2000]))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Length for sentence number 100:  5\n","Length for sentence number 2000:  9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NoPv4Lngfl7K","colab_type":"text"},"source":["### How do we make it same?"]},{"cell_type":"markdown","metadata":{"id":"5PMMBddPfl7L","colab_type":"text"},"source":["### Padding the sentences"]},{"cell_type":"code","metadata":{"id":"mZteu7yOfl7M","colab_type":"code","colab":{}},"source":["#Source sentences\n","encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n","                                                                   maxlen=max_encoder_seq_length, #22\n","                                                                   padding='pre')\n","\n","#Target Sentences\n","decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n","                                                                   maxlen=max_decoder_seq_length, #27\n","                                                                   padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfpWaKgMfl7U","colab_type":"code","outputId":"b9618386-6fe3-4d7d-f933-cc35cd71c656","executionInfo":{"status":"ok","timestamp":1578047599920,"user_tz":-330,"elapsed":1130,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print('Source data shape: ', encoder_input_data.shape)\n","print('Target data shape: ', decoder_input_data.shape)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Source data shape:  (2785, 22)\n","Target data shape:  (2785, 27)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"miayBNRKfl7Z","colab_type":"code","outputId":"34ed2cba-dfb9-416a-f5c0-b8a592ecc426","executionInfo":{"status":"ok","timestamp":1578047613044,"user_tz":-330,"elapsed":1314,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["encoder_text[0]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Wow!'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"oZP5sXFMfl7c","colab_type":"code","outputId":"69d5beb1-d583-442f-ec1b-ccb97b5a6e27","executionInfo":{"status":"ok","timestamp":1578047617370,"user_tz":-330,"elapsed":909,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["encoder_input_data[0]"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1267],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"fxsmfT_Bfl7g","colab_type":"code","outputId":"a2e84458-99c6-4ea8-9220-9b20ad62f727","executionInfo":{"status":"ok","timestamp":1578047651977,"user_tz":-330,"elapsed":1628,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder_text[0]"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> वाह! <end>'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"PKLwi-xkfl7k","colab_type":"code","outputId":"e6e9a585-fa21-4566-a23c-735c2ea5311c","executionInfo":{"status":"ok","timestamp":1578047658376,"user_tz":-330,"elapsed":1330,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["decoder_input_data[0]"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  1, 752,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"YF4DUwvpfl7n","colab_type":"text"},"source":["#### Integer to Word converter for Decoder data"]},{"cell_type":"code","metadata":{"id":"ySTFFvTafl7o","colab_type":"code","colab":{}},"source":["int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEXTTKm-fl7q","colab_type":"code","outputId":"524b66df-6729-4d05-eb92-936444e56101","executionInfo":{"status":"ok","timestamp":1578047720122,"user_tz":-330,"elapsed":1985,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["int_to_word_decoder[3]"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'है।'"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"bR9aockMfl7s","colab_type":"text"},"source":["### Building Decoder Output"]},{"cell_type":"code","metadata":{"id":"Jlc4nfysfl7t","colab_type":"code","outputId":"72273b9a-ee65-46d1-f803-44da212d20a4","executionInfo":{"status":"ok","timestamp":1578047839516,"user_tz":-330,"elapsed":1147,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder_input_data.shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2785, 27)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"Gr3ZiB8Wfl7v","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","#Initialize array\n","decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n","\n","#Shift Target output by one word\n","for i in range(decoder_input_data.shape[0]):\n","    for j in range(1,decoder_input_data.shape[1]):\n","        decoder_target_data[i][j-1] = decoder_input_data[i][j]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdYOsmcEAAhl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"e4cc19a4-8b67-4085-bfcb-1713d962e728","executionInfo":{"status":"ok","timestamp":1578048165798,"user_tz":-330,"elapsed":1333,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["decoder_input_data"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   1,  752,    2, ...,    0,    0,    0],\n","       [   1, 1446,    2, ...,    0,    0,    0],\n","       [   1, 1447,    2, ...,    0,    0,    0],\n","       ...,\n","       [   1, 2967,  750, ...,    0,    0,    0],\n","       [   1,  135,   60, ...,    0,    0,    0],\n","       [   1,  131,    6, ...,   26,  153,    2]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"kbkUt6PX_GpY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"16ed2e49-d1dc-4c06-a934-5ce1134ff8e8","executionInfo":{"status":"ok","timestamp":1578047934441,"user_tz":-330,"elapsed":1115,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["decoder_target_data"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[7.520e+02, 2.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [1.446e+03, 2.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [1.447e+03, 2.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       ...,\n","       [2.967e+03, 7.500e+02, 1.800e+01, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [1.350e+02, 6.000e+01, 1.333e+03, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [1.310e+02, 6.000e+00, 5.110e+02, ..., 1.530e+02, 2.000e+00,\n","        0.000e+00]])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"B5rY-a3Pfl7y","colab_type":"code","colab":{}},"source":["#decoder_t.word_index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"len4F7pkfl71","colab_type":"code","colab":{}},"source":["#<start> yeh kitab hai <end>\n","#Yeh kitab hai <end> 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujM8blLdfl77","colab_type":"code","outputId":"c8bad613-db24-4de7-b43c-e24145b27a41","executionInfo":{"status":"ok","timestamp":1572690164340,"user_tz":-330,"elapsed":6086,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["decoder_input_data[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  1, 752,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"YIORb0-3fl7-","colab_type":"code","outputId":"d2ea67b7-a3dd-45af-9e6b-9b1d78e315a2","executionInfo":{"status":"ok","timestamp":1572690164340,"user_tz":-330,"elapsed":6056,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["decoder_target_data[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([752.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.])"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"markdown","metadata":{"id":"nDyO3nQUfl8A","colab_type":"text"},"source":["#### Convert target data in one hot vector"]},{"cell_type":"code","metadata":{"id":"o2U1OCtMfl8B","colab_type":"code","colab":{}},"source":["#Initialize one hot encoding array\n","decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n","                                   decoder_input_data.shape[1], #Number of words in each sentence\n","                                   len(decoder_t.word_index)+1)) #Vocab size + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4-U7rWtfl8D","colab_type":"code","outputId":"6cbe0049-f8fe-4609-d269-923a59a2ea6e","executionInfo":{"status":"ok","timestamp":1578051118357,"user_tz":-330,"elapsed":1727,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder_target_one_hot.shape"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2785, 27, 2975)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"aum2qfX2fl8G","colab_type":"code","colab":{}},"source":["#Build one hot encoded array\n","for i in range(decoder_target_data.shape[0]):\n","    for j in range(decoder_target_data.shape[1]):\n","        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n","                                                                     num_classes=len(decoder_t.word_index)+1)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzeFq0Nffl8K","colab_type":"code","outputId":"1ada1e38-9ad2-4737-e6f8-b1f76c077169","executionInfo":{"status":"ok","timestamp":1578051229024,"user_tz":-330,"elapsed":1304,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder_target_one_hot.shape"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2785, 27, 2975)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"5yTTFxIzfl8N","colab_type":"text"},"source":["### Building the Training Model"]},{"cell_type":"code","metadata":{"id":"2WWQaJdwfl8O","colab_type":"code","colab":{}},"source":["#Define config parameters\n","encoder_embedding_size = 50\n","decoder_embedding_size = 50\n","rnn_units = 256"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3X2v2rwffl8Q","colab_type":"text"},"source":["#### Build Encoder"]},{"cell_type":"code","metadata":{"id":"LKHCtheVfl8Q","colab_type":"code","colab":{}},"source":["#Input Layer\n","encoder_inputs = tf.keras.layers.Input(shape=(None,))\n","\n","#Embedding layer\n","encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n","\n","#Get embedding layer output by feeding inputs\n","encoder_embedding_output = encoder_embedding(encoder_inputs)\n","\n","#LSTM Layer and its output\n","x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n","\n","#Build a list to feed Decoder - Sentence Embedding\n","encoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"alp5BJQEfl8S","colab_type":"code","outputId":"f5a155d5-54bd-4f0c-c272-01036c4ee207","executionInfo":{"status":"ok","timestamp":1578052521996,"user_tz":-330,"elapsed":1340,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["encoder_embedding_output"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'embedding_2/embedding_lookup/Identity_1:0' shape=(?, ?, 50) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"loyHsw7Rfl8V","colab_type":"text"},"source":["#### Build Decoder"]},{"cell_type":"code","metadata":{"id":"_9TjwmvIfl8W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ea39279e-049e-4567-e8c9-6dd8adfa72b4","executionInfo":{"status":"ok","timestamp":1578055586473,"user_tz":-330,"elapsed":1314,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["#Decode input - padded Target sentences\n","decoder_inputs = tf.keras.layers.Input(shape=(None,))\n","\n","#Decoder Embedding layer\n","decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n","\n","#Embedding layer output\n","decoder_embedding_output = decoder_embedding(decoder_inputs)\n","\n","#Decoder RNN\n","decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n","\n","#Decoder RNN Output, State initialization from Encoder states\n","#Output will be all hidden sequences, last 'h' state and last 'c' state\n","x,_,_ = decoder_rnn(decoder_embedding_output, initial_state=encoder_states)\n","\n","#Output Layer\n","decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n","\n","#Output of Dense layer\n","decoder_outputs = decoder_dense(x)\n","print(x.shape)"],"execution_count":88,"outputs":[{"output_type":"stream","text":["(?, ?, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qUNgO2QFUOeh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"09b5c535-2279-430c-913e-049c48c37916","executionInfo":{"status":"ok","timestamp":1578055591385,"user_tz":-330,"elapsed":1315,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["x.shape"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(256)])"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"K3PZJeAVfl8c","colab_type":"code","outputId":"051e0170-c22c-439f-e38b-2f5c49b06a3a","executionInfo":{"status":"ok","timestamp":1578055592770,"user_tz":-330,"elapsed":1328,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder_outputs"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'dense_4/truediv:0' shape=(?, ?, 2975) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"markdown","metadata":{"id":"k5Yf-VMHfl8h","colab_type":"text"},"source":["### Build Model using both Encoder and Decoder"]},{"cell_type":"code","metadata":{"id":"Eu7NLORzfl8i","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n","                              decoder_outputs) #Output of the model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmp43leZfl8k","colab_type":"code","outputId":"fba84075-7f42-4f7b-a297-9ae0e13c1f93","executionInfo":{"status":"ok","timestamp":1578055599431,"user_tz":-330,"elapsed":1090,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["model.output"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'dense_4/truediv:0' shape=(?, ?, 2975) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"zPGyS1FBfl8n","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwCw8C0Ifl8s","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"JVRXU4Arfl8v","colab_type":"code","outputId":"440f2746-b718-4d71-8e01-f98a030eb498","executionInfo":{"status":"ok","timestamp":1578055663209,"user_tz":-330,"elapsed":56930,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n","          batch_size=64,\n","          epochs=2,\n","          validation_split=0.2)"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Train on 2228 samples, validate on 557 samples\n","Epoch 1/2\n","2228/2228 [==============================] - 29s 13ms/sample - loss: 3.4357 - val_loss: 3.0096\n","Epoch 2/2\n","2228/2228 [==============================] - 26s 12ms/sample - loss: 1.6193 - val_loss: 3.0071\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7053659390>"]},"metadata":{"tags":[]},"execution_count":94}]},{"cell_type":"markdown","metadata":{"id":"5Ytdt1zHfl8x","colab_type":"text"},"source":["### Save the model for later reuse"]},{"cell_type":"code","metadata":{"id":"VoSQZ_e3fl8y","colab_type":"code","colab":{}},"source":["model.save('seq2seq_training_translation.hd5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pRSCZlnwfl81","colab_type":"text"},"source":["# Building Model for Prediction"]},{"cell_type":"markdown","metadata":{"id":"cOkrK0Qafl82","colab_type":"text"},"source":["### Build the Encoder Model to predict Encoder States"]},{"cell_type":"code","metadata":{"id":"RrgzlE4Bfl83","colab_type":"code","colab":{}},"source":["encoder_model = tf.keras.models.Model(encoder_inputs, #Padded input sequences\n","                                      encoder_states) #Hidden state and Cell state at last time step"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jIpk0ZC5fl84","colab_type":"text"},"source":["### Build the Decoder Model \n","<p/>\n","\n","<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n","<li>Get Decoder RNN outputs along with h and c state</li>\n","<li>Get Decoder Dense layer output</li>\n","        <li>Build Model</li></ol>"]},{"cell_type":"markdown","metadata":{"id":"1OaSO0L9fl85","colab_type":"text"},"source":["##### Step 1 - Define Input for both 'h' state and 'c' state initialization"]},{"cell_type":"code","metadata":{"id":"BONW8gMvfl85","colab_type":"code","colab":{}},"source":["#Hidden state input\n","decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Cell state input\n","decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Putting it together\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cr8JFgAdfl88","colab_type":"text"},"source":["##### Step 2 - Get Decoder RNN outputs along with h and c state"]},{"cell_type":"code","metadata":{"id":"qkA0HTR9fl8-","colab_type":"code","colab":{}},"source":["#Get Embedding layer output\n","x = decoder_embedding(decoder_inputs)\n","\n","#We will use the layer which we trained earlier\n","rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n","\n","#Why do we need this?\n","decoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZqVxg6Qfl9A","colab_type":"text"},"source":["##### Step 3 - Get Decoder Dense layer output"]},{"cell_type":"code","metadata":{"id":"RW-X1-edfl9B","colab_type":"code","colab":{}},"source":["decoder_outputs = decoder_dense(rnn_outputs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqX2Euiofl9C","colab_type":"text"},"source":["##### Step 4 - Build Decoder Model"]},{"cell_type":"code","metadata":{"id":"PPPqaTigfl9D","colab_type":"code","colab":{}},"source":["decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,  #Model inputs\n","                                      [decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vpYhI4e6fl9E","colab_type":"text"},"source":["# Predicting output from Seq2Seq model"]},{"cell_type":"markdown","metadata":{"id":"gR6eh8wEfl9F","colab_type":"text"},"source":["##### Build a prediction function"]},{"cell_type":"code","metadata":{"id":"eUK2Wogyfl9K","colab_type":"code","colab":{}},"source":["def decode_sentence(input_sequence):\n","    \n","    #Get the encoder state values - Sentence embedding\n","    decoder_initial_states_value = encoder_model.predict(input_seq)\n","    \n","    #Build a sequence with '<start>' - starting sequence for Decoder\n","    target_seq = np.zeros((1,1))    \n","    target_seq[0][0] = decoder_t.word_index['start']\n","    \n","    #flag to check if prediction should be stopped\n","    stop_loop = False\n","    \n","    #Initialize predicted sentence\n","    predicted_sentence = ''\n","    \n","    num_of_predictions = 0\n","    \n","    #start the loop\n","    while not stop_loop:\n","        \n","        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n","                                                        decoder_initial_states_value)\n","        \n","        #Get the predicted word index with highest probability\n","        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n","        \n","        #Get the predicted word from predicter index\n","        predicted_word = int_to_word_decoder[predicted_output]\n","        \n","        #Check if prediction should stop\n","        if(predicted_word == 'end' or num_of_predictions > max_decoder_seq_length):\n","            \n","            stop_loop = True\n","            continue\n","        \n","        #num_of_predictions += 1\n","        #predicted_sentence = predicted_sentence + ' ' + predicted_word\n","        #Updated predicted sentence\n","        if (len(predicted_sentence) == 0):\n","            predicted_sentence = predicted_word\n","        else:\n","            predicted_sentence = predicted_sentence + ' ' + predicted_word\n","            \n","        #Update target_seq to be the predicted word index\n","        target_seq[0][0] = predicted_output\n","        \n","        #Update initial states value for decoder\n","        decoder_initial_states_value = [h,c]\n","        \n","    \n","    return predicted_sentence"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vHLS9TMfl9P","colab_type":"text"},"source":["##### Call Prediction function on a random sentence"]},{"cell_type":"code","metadata":{"id":"b2tW3GWEaKaV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"27d055b8-bfa4-407c-a1e7-34395f20d11f","executionInfo":{"status":"ok","timestamp":1578055118516,"user_tz":-330,"elapsed":1093,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["#Generate a random number\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","start_num"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["161"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"ad62DzUCfl9P","colab_type":"code","outputId":"ba256500-ef01-42b7-9867-51dd72ee0fdf","executionInfo":{"status":"ok","timestamp":1578055123896,"user_tz":-330,"elapsed":1084,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}},"colab":{"base_uri":"https://localhost:8080/","height":277}},"source":["#Generate a random number\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","\n","#Predict model output for 5 sentences\n","for i in range(start_num, start_num + 5):\n","    input_seq = encoder_input_data[i : i+1]\n","    predicted_sentence = decode_sentence(input_seq)\n","    print('--------')\n","    print ('Input sentence: ', encoder_text[i])\n","    print ('Predicted sentence: ', predicted_sentence )"],"execution_count":86,"outputs":[{"output_type":"stream","text":["--------\n","Input sentence:  Workers must have their hair cut short.\n","Predicted sentence:  मैं मैं\n","--------\n","Input sentence:  Would you mind turning down the volume?\n","Predicted sentence:  मैं मैं\n","--------\n","Input sentence:  You must observe the rules of the club.\n","Predicted sentence:  मैं मैं\n","--------\n","Input sentence:  You've got a nerve to say such a thing!\n","Predicted sentence:  मैं मैं\n","--------\n","Input sentence:  Your examination results are excellent.\n","Predicted sentence:  मैं मैं\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jCMUpP31fl9S","colab_type":"text"},"source":["##### Save encoder and decoder model"]},{"cell_type":"code","metadata":{"id":"3hlchg1Bfl9T","colab_type":"code","colab":{}},"source":["#Compile models to avoid error\n","encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","\n","#Save the models\n","encoder_model.save('seq2seq_encoder_eng_hin.hd5')  #Encoder model\n","decoder_model.save('seq2seq_decoder_eng_hin.hd5')  #Decoder model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSuU4WRxfl9U","colab_type":"text"},"source":["##### Save encoder and decoder tokenizers"]},{"cell_type":"code","metadata":{"id":"kLxRy_qKfl9V","colab_type":"code","colab":{}},"source":["import pickle\n","\n","pickle.dump(encoder_t,open('encoder_tokenizer_eng','wb'))\n","pickle.dump(decoder_t,open('decoder_tokenizer_hin','wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1K3QuBx5eOhk","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","edModelcheckpoint_path = \"/home/narayana/wd/codes/finance/savedModels/edModel.ckpt\"\n","\n","nStepsIn = 1\n","nStepsOut = 1\n","\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.LSTM(128, activation='relu', input_shape=(nStepsIn, X_train.shape[2])))\n","model.add(tf.keras.layers.RepeatVector(nStepsOut))\n","model.add(tf.keras.layers.LSTM(128, activation='relu', return_sequences=True))\n","model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_classes, activation='softmax')))\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=edModelcheckpoint_path,\n","                                                 save_weights_only=True,\n","                                                 monitor='loss',\n","                                                 mode = 'min',\n","                                                 save_best_only=True,\n","                                                 verbose=1)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","y_train_copy = y_train.copy()\n","y_test_copy = y_test.copy()\n","y_train_copy = np.reshape(y_train_copy, (y_train_copy.shape[0], 1, y_train_copy.shape[1]))\n","y_test_copy = np.reshape(y_test_copy, (y_test_copy.shape[0], 1, y_test_copy.shape[1]))\n","\n","model.fit(X_train, y_train_copy, epochs=100, validation_data=(X_test, y_test_copy), batch_size=32, callbacks=[cp_callback])\n","# Loads the weights\n","model.load_weights(edModelcheckpoint_path)\n","loss_and_metrics = model.evaluate(X_train, y_train_copy)\n","print(loss_and_metrics)\n","loss_and_metrics = model.evaluate(X_test, y_test_copy)\n","print(loss_and_metrics)"],"execution_count":0,"outputs":[]}]}